{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch SageMaker Training Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Sagemaker pytorch docs](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html)\n",
    "\n",
    "## 3 Steps for Training\n",
    "\n",
    "1. Prepare a training script\n",
    "\n",
    "2. Create a sagemaker.pytorch.PyTorch Estimator\n",
    "\n",
    "3. Call the estimatorâ€™s fit method\n",
    "\n",
    "Prepare your script in a separate source file than the notebook\n",
    "\n",
    "* `SM_NUM_GPUS`: number of GPUs.\n",
    "\n",
    "* `SM_MODEL_DIR`: path to the S3 directory to write model artifacts to.\n",
    "\n",
    "* `SM_OUTPUT_DATA_DIR`: Write Output artifacts such as: checkpoints, graphs, and other files to save, not including model artifacts.\n",
    "\n",
    "* `SM_CHANNEL_XXXX`: Either `SM_CHANNEL_TRAIN` and `SM_CHANNEL_TEST` input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example script\n",
    "```python\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument('--epochs', type=int, default=50)\n",
    "    parser.add_argument('--batch-size', type=int, default=64)\n",
    "    parser.add_argument('--learning-rate', type=float, default=0.05)\n",
    "    parser.add_argument('--use-cuda', type=bool, default=False)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "    parser.add_argument('--test', type=str, default=os.environ['SM_CHANNEL_TEST'])\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # ... load from args.train and args.test, train a model, write model to args.model_dir.\n",
    "```\n",
    "For training, SageMaker simply exectues the provided script as main. However, during deploying if you're using the same script, you should put your training code in a main guard (`if __name__=='__main__':`), because the SageMaker imports your training script.\n",
    "\n",
    "Note that SageMaker doesn't support argparse. Instead it relies on [Environment Variables](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md)\n",
    "\n",
    "If there are other packages you want to use with your script, you can include a `requirements.txt` file in the same directory as your training script to install other dependencies at runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pytorch Model\n",
    "\n",
    "```python\n",
    "# https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/pytorch_mnist/mnist.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "#...\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        # ...\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # ...\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data loaders\n",
    "\n",
    "Create two private functions for loading training and testing data, e.g. `_get_train_data_loader` & `_get_test_data_loader`\n",
    "\n",
    "```python\n",
    "def _get_train_data_loader(batch_size, training_dir, is_distributed, **kwargs):\n",
    "    logger.info(\"Get train data loader\")\n",
    "    dataset = datasets.MNIST(training_dir, train=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ]))\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset) if is_distributed else None\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=train_sampler is None,\n",
    "                                       sampler=train_sampler, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define train function\n",
    "```python\n",
    "def train(args):\n",
    "    is_distributed = len(args.hosts) > 1 and args.backend is not None\n",
    "    logger.debug(\"Distributed training - {}\".format(is_distributed))\n",
    "    use_cuda = args.num_gpus > 0\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # ...\n",
    "    \n",
    "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir, is_distributed, **kwargs)\n",
    "    model = Net().to(device)\n",
    "    # ...\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader, 1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            if is_distributed and not use_cuda:\n",
    "                # average gradients manually for multi-machine cpu case only\n",
    "                _average_gradients(model)\n",
    "            optimizer.step()\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                logger.info('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.sampler),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "        test(model, test_loader, device)\n",
    "    save_model(model, args.model_dir)\n",
    "    \n",
    "def test(model, test_loader, device):\n",
    "    # ...\n",
    "    \n",
    "def model_fn(model_dir):\n",
    "    '''\n",
    "    Before a model can be served, it must be loaded.\n",
    "    The SageMaker PyTorch model server loads your model by invoking a model_fn function\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.nn.DataParallel(Net())\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def save_model(model, model_dir):\n",
    "    logger.info(\"Saving the model.\")\n",
    "    path = os.path.join(model_dir, 'model.pth')\n",
    "    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
    "    torch.save(model.cpu().state_dict(), path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Functions (Deploying)\n",
    "\n",
    "* `model_fn(model_dir)` - loads your model.\n",
    "* `input_fn(serialized_input_data, content_type)` - deserializes predictions to predict_fn.\n",
    "* `output_fn(prediction_output, accept)` - serializes predictions from predict_fn.\n",
    "* `predict_fn(input_data, model)` - calls a model on data deserialized in input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
